CQ1:  A) Given the above scenario, how many moves are likely needed each time we do a delete_min()? 
    Assuming the array is 5, we know that the min value can be 1-4 or 5 so if we take an average
    we get that 3 moves are most likely needed.
B) How many times will we do a delete_min() on this graph? 
    20 times. one for each vertex.
C) What is the expected total number of moves across all the calls to delete_min()? 
    20*3 = 60 moves
D) If the time taken by one loop iteration inside of delete_min for moving an array element is half a nanosecond, and the overhead involved in each call to delete_min() (other than the loop) is 10 nanoseconds, then how much time do we expect to be used by calls to delete_min() for this graph, overall? 
    20(10+3*10) = 800 nanoseconds

CQ2:  A) Given the above scenario, how many moves are likely needed each time we do a delete_min()? 
    1000/2 = 500 moves
B) How many times will we do a delete_min() on this graph?
    100000
C) What is the expected total number of moves across all the calls to delete_min()?
   100000*1000/2 = 50000000 moves
D) If the time taken by one loop iteration inside of delete_min for moving an array element is half a nanosecond, and the overhead involved in each call to delete_min() (other than the loop) is 10 nanoseconds, then how much time do we expect to be used by calls to delete_min() for this graph, overall?
   100000(0.5*500+10) = 26000000 nanoseconds
 
CQ3:  A) Do these assumptions for the time required for one call to insert(), or one call to  decrease_key(), seem realistic?  Why or why not?
    Yes, since it is easily more computated than delete minimum
B) If we use all the above assumptions, how many nanoseconds would you expect to be caused by all the calls to nearby()?  Justify your answer.
    It really depends on how many neighbors a town has. Since the average is 4,
    than it take about 50 nanoseconds
    function nearby(u)
    This would say how long approzimately it would take for each line
    for neighbor v of u               4*

      if v is not in lockdown         1

        t <- u.day + uv.delay         1

        if v.warn > t                 2

          v.warn <- t                 2

          if v.warn started out empty 1

            insert(t, v)              1

          else                        1    

            decrease_key(v, t)        2
C) Which is larger:  the time invested in all the calls to nearby(), or all the calls to delete_min()? 
    nearby()
D) Given all these assumptions, what would be the total time taken to solve the pandemic puzzle with panC_plain?
    102400  
 
CQ4:  A) Given the above scenario, how many swaps are likely needed each time we do an insert()? 
    2swaps
B) How many swaps are likely needed each time we do a decrease_key()?
    2swaps
C) How many times will we do an insert() for this graph?
    20
D) Suppose we end up calling decrease_key() half as often as we do insert().
   D) If the time taken by one loop iteration inside of insert() or decrease_key() is half a nanosecond, and the overhead involved in each call to insert() or decrease_key() (other than the loop) is 10 nanoseconds, then how much time do we expect to be used by calls to insert() or decrease_key() for this graph, overall?
    0.5(20+10) = 15 nanoseconds

CQ5:  A) Given the above scenario, how many swaps are likely needed each time we do an insert() operation?
    499 swaps
B) What is the expected total number of swaps across all the calls to insert() and decrease_key()?
    1000 swaps
C)  If the time taken by one loop iteration inside of insert() or decrease_key() is half a nanosecond, and the overhead involved in each call to insert() or decrease_key() (other than the loop) is 10 nanoseconds, then how much time do we expect to be used by calls to insert() and decrease_key() for this graph, overall?
    10000000 nanoseconds

CQ6:  A) Do these assumptions for the time required for one call to delete_min() seem realistic?  Why or why not?
    No since the time seems to be short
B) Given all the above assumptions, how many nanoseconds would you expect to be caused by all the calls to delete_min()?  Justify your answer.
    0 nanoseconds, since each call takes 2 nanoseconds and there are 20 calls
C) Which is larger:  the cost of all the calls to nearby(), or all the calls to delete_min()? 
    nearby()
D) Given all these assumptions, what would be the total time taken to solve the pandemic puzzle with panC_sorted?
    1000000000 nanoseconds

CQ7:  Review:  what is the formula for the sum of the first n+1 powers of 3, that is, what is the formula for the sum  1 + 3 + 32 + â€¦ + 3n?
    Sn = a(1-r^n)/(1-r)

CQ8:  A) In the exercise r4 above (with two recursive calls inside the r4 function), what formula could we use to describe how many function calls would be made for r4(j), for some value j?  Explain your answer.
    Sn = a(1-r^n)/(1-r) where r = 2 start value is 1 and n is the height.
B) In the exercise r4b above (with three recursive calls inside the r4b function), what formula could we use to describe how many function calls would be made for r4b(j), for some value j?  Explain your answer. 
    Sn = a(1-r^n)/(1-r) where r = 3 start is 1 and n is height
C) If we had another recursive function r4c that had d recursive calls (where d could be two, or three, or something larger), what formula could we use to describe how many function calls would be made for r4c(j), for some value j?
    Sn = a(1-r^n)/(1-r) r = d, 1 = start and n = height 

CQ9:  Explain heap insert in your own words.
    It is basically ordering inputs of values into the memory

CQ10:  Explain decrease_key() in your own words.
    Reorders the values of an array

CQ11:  Explain delete_min() in your own words.
    Deletes the element with the highest priority

CQ12:  Which of these three operations (insert, decrease_key, or delete_min) would you expect to be the most expensive for large heaps?
    Delete_min seems to be more expensive than heaps
